{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Examples of how to build concept-based explanations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load the model and list modules to find where to split it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[('model', EuroBertModel(\n",
                        "  (embed_tokens): Embedding(128256, 768, padding_idx=128001)\n",
                        "  (layers): ModuleList(\n",
                        "    (0-11): 12 x EuroBertDecoderLayer(\n",
                        "      (self_attn): EuroBertAttention(\n",
                        "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
                        "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
                        "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
                        "        (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
                        "      )\n",
                        "      (mlp): EuroBertMLP(\n",
                        "        (gate_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
                        "        (up_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
                        "        (down_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
                        "        (act_fn): SiLU()\n",
                        "      )\n",
                        "      (input_layernorm): EuroBertRMSNorm((768,), eps=1e-05)\n",
                        "      (post_attention_layernorm): EuroBertRMSNorm((768,), eps=1e-05)\n",
                        "    )\n",
                        "  )\n",
                        "  (norm): EuroBertRMSNorm((768,), eps=1e-05)\n",
                        "  (rotary_emb): EuroBertRotaryEmbedding()\n",
                        ")), ('lm_head', Linear(in_features=768, out_features=128256, bias=False))]\n"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
                "\n",
                "model = AutoModelForMaskedLM.from_pretrained(\"EuroBERT/EuroBERT-210m\", trust_remote_code=True)\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"EuroBERT/EuroBERT-210m\")\n",
                "split_point = \"model.layers.10.mlp\"\n",
                "\n",
                "print(list(model.named_children()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Split the model using the `ModelWithSplitPoints` class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from interpreto import ModelWithSplitPoints\n",
                "\n",
                "splitted_model = ModelWithSplitPoints(\n",
                "    model_or_repo_id=model,\n",
                "    tokenizer=tokenizer,\n",
                "    split_points=split_point,\n",
                "    device_map=\"cuda\",\n",
                "    batch_size=64,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load the dataset and compute activations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([187890, 768])\n"
                    ]
                }
            ],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "rotten_tomatoes = load_dataset(\"cornell-movie-review-data/rotten_tomatoes\")[\"train\"][\"text\"]\n",
                "\n",
                "activations = splitted_model.get_activations(\n",
                "    rotten_tomatoes,\n",
                "    activation_granularity=ModelWithSplitPoints.activation_granularities.WORD,\n",
                ")\n",
                "\n",
                "print(activations[split_point].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create and fit the concept explainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/antonin.poche/interpreto/.venv/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "from interpreto.concepts import ICAConcepts\n",
                "\n",
                "concept_explainer = ICAConcepts(splitted_model, nb_concepts=50)\n",
                "\n",
                "concept_explainer.fit(activations)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpret the concepts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from interpreto.concepts.interpretations import TopKInputs\n",
                "\n",
                "interpretations = concept_explainer.interpret(\n",
                "    TopKInputs,\n",
                "    concepts_indices=\"all\",\n",
                "    source=TopKInputs.sources.LATENT_ACTIVATIONS,\n",
                "    granularity=TopKInputs.granularities.WORD,\n",
                "    inputs=rotten_tomatoes,\n",
                "    latent_activations=activations,\n",
                "    k=10,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Concept 0: [' all', ' everything', ' two', ' under', ' beyond', ' below', ' above', ' self', ' sibling', ' southern']\n",
                        "Concept 1: [' see', ' watching', ' watch', ' view', ' seen', ' find', ' seeing', ' admire', ' sees', ' look']\n",
                        "Concept 2: [' to', ' about', ' will', ' in', ' and', ' with', ' of', ' that', ' out', ' feels']\n",
                        "Concept 3: [' doesn', ' does', ' believes', ' thing', ' to', ' into', ' of', ' claims', ' promises', ' cannot']\n",
                        "Concept 4: [' in', '-in', 'in', ' en', ' into', ' em', ' inside', ' within', ' on', ' at']\n",
                        "Concept 5: [' of', 'of', ' de', ' or', ' del', ' da', ' to', ' dos', '-of', ' do']\n",
                        "Concept 6: [' like', ' as', ' be', ' apparently', ' corrupt', ' cult', ' supernatural', ' shot', ' towering', ' skin']\n",
                        "Concept 7: [' one', ' on', ' end', ' upon', ' photographed', '-on', ' next', ' start', ' may', ' first']\n",
                        "Concept 8: [' reason', ' admirable', ' reasons', ' genesis', ' love', ' thing', ' success', ' passion', ' wonderful', ' emerged']\n",
                        "Concept 9: [' on', ' through', ' into', ' up', ' mind', ' to', ' forward', ' may', ' minds', ' along']\n",
                        "Concept 10: [' a', ' an', 'a', ' another', ' one', 'an', ' some', 'one', ' um', '-a']\n",
                        "Concept 11: [' to', ' be', ' note', 'not', ' takes', ' not', ' didn', ' testimony', ' give', ' done']\n",
                        "Concept 12: [' with', 'with', ' com', ' con', '\\x85with', ' by', ' appreciate', ' using', ' to', ' like']\n",
                        "Concept 13: [' i', 'i', ' me', ' my', ' am', 'my', \"'m\", ' eu', ' myself', ' mine']\n",
                        "Concept 14: ['.', ',', ' )', ' *', ' -', ' t', ' (', '?', ' s', '+']\n",
                        "Concept 15: ['.', '!', ',', '?', ' )', \"'\", \" '\", ' \"', ' ;', '-']\n",
                        "Concept 16: [' surprising', ' breakthrough', ' believe', ' superb', ' most', ' wait', ' astonishing', ' time', ' impressive', ' complete']\n",
                        "Concept 17: [' life', ' say', ' sweet', ' on', ' when', ' mature', ' of', ' love', ' ends', ' do']\n",
                        "Concept 18: [' from', ' behind', 'from', ' than', ' beneath', ' front', ' moving', ' stuck', ' here', ' turned']\n",
                        "Concept 19: [' and', 'and', '-and', ' y', ' &', ' e', ' or', ' as', ' nor', ',']\n",
                        "Concept 20: [' hit', ' hitting', ' relentlessly', ' killed', ' doesn', ' don', ' extreme', ' have', ' won', ' derive']\n",
                        "Concept 21: [' may', ' can', ' could', ' might', ' would', ' will', ' must', ' wouldn', ' won', 'may']\n",
                        "Concept 22: [' still', ' simply', ' nevertheless', ' certainly', ' also', ' ultimately', ' even', ' definitely', ' equally', ' similarly']\n",
                        "Concept 23: [' text', ' filled', ' if', ' as', ' clear', ' time', ' line', ' impossible', ' adapted', ' title']\n",
                        "Concept 24: [' maze', ' swamp', ' yarn', ' bowl', ' pony', ' mess', ' truck', ' bag', ' wreck', ' whirl']\n",
                        "Concept 25: [' continues', ' has', ' further', ' only', ' later', ' ongoing', '-in', ' update', ' summer', ' new']\n",
                        "Concept 26: [' rip', ' sink', ' shines', ' thump', ' collapses', ' sting', ' butt', ' bites', ' hums', ' suck']\n",
                        "Concept 27: [' between', ' separates', ' typical', ' comes', ' need', ' from', ' prove', ' usual', ' fit', ' much']\n",
                        "Concept 28: [' of', ' kind', ' intelligible', ' like', ' any', ' from', ' seem', ' treatises', ' devoid', ' story']\n",
                        "Concept 29: ['it', 'a', 'if', 'at', 'the', 'in', 'as', 'not', 'there', 'no']\n",
                        "Concept 30: [' see', ' all', ' every', ' missing', ' through', ' catch', ' displaying', ' gets', ' watch', ' use']\n",
                        "Concept 31: [' little', \"'\", ' into', ' and', ' path', ' with', ' through', ' between', '-school', ' of']\n",
                        "Concept 32: [' makes', ' seen', ' seem', ' thoughtful', ' often', ' were', ' like', ' two', ' many', ' kind']\n",
                        "Concept 33: ['.', ' and', ' has', 'odd', ' poo', 'a', 'cinematic', ' very', ' ride', ' sometimes']\n",
                        "Concept 34: [',', ' )', ' ;', ' :', ' --', '.', '?', ' -', '!', ' \"']\n",
                        "Concept 35: [' on', ' about', ' upon', ' at', 'about', ' over', ' into', ' sobre', ' what', ' how']\n",
                        "Concept 36: [' get', ' subtle', ' like', ' what', ' \"', ' four', ' three', \"'\", ' stark', ' don']\n",
                        "Concept 37: [' makes', ' make', ' made', ' lifts', ' leaves', ' making', ' render', ' sent', ' leave', ' keep']\n",
                        "Concept 38: [' rare', ' little', ' greatly', ' desperate', ' fierce', ' big', ' mountain', ' distant', ' grand', ' struggle']\n",
                        "Concept 39: [' joan', 'payne', ' huston', 'cho', ' jonah', ' genet', ' chan', ' eyre', 'ne', ' jonze']\n",
                        "Concept 40: [' by', ' from', ' por', 'by', ' pelo', 'from', ' since', ' da', ' through', ' at']\n",
                        "Concept 41: [' that', ' which', ' who', ' que', ' whose', ' whom', ' new', 'what', ' qui', ' what']\n",
                        "Concept 42: [' is', ' isn', ' was', ' are', ' wasn', ' aren', ' doesn', ' were', ' be', 'is']\n",
                        "Concept 43: [' the', 'this', 'the', ' this', 'these', ' these', 'that', ' those', ' that', ' his']\n",
                        "Concept 44: [' observations', ' insight', ' life', ' error', ' vision', ' investigation', ' experience', ' environment', ' effort', ' into']\n",
                        "Concept 45: [' most', ' mainstream', ' mainly', ' mediocre', ' general', ' mostly', 'most', ' certain', ' typical', ' completely']\n",
                        "Concept 46: [' lesser', '-fashioned', ' had', ' simplistic', ' primitive', ' inferior', ' just', ' disparate', '-made', ' mundane']\n",
                        "Concept 47: [' off', ' death', ' out', ' chair', ' on', ' skin', ' seconds', ' time', ' door', ' way']\n",
                        "Concept 48: [' inhabit', ' below', ' expressed', ' reflect', ' haunting', ' live', ' beneath', ' indulge', ' deferred', ' distancing']\n",
                        "Concept 49: [' sur', ' twists', ' on', ' hours', ' hour', ' weeks', ' includes', ' onto', ' first', ' charm']\n"
                    ]
                }
            ],
            "source": [
                "for concept_id, words_importance in interpretations.items():\n",
                "    print(f\"Concept {concept_id}: {list(words_importance.keys()) if words_importance is not None else 'None'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "from interpreto.concepts.interpretations.llm_labels import SAMPLING_METHOD, LLMLabels\n",
                "from interpreto.model_wrapping.llm_interface import OpenAILLM\n",
                "from interpreto.model_wrapping.model_with_split_points import ActivationGranularity\n",
                "\n",
                "interpretations = concept_explainer.interpret(\n",
                "    LLMLabels,\n",
                "    concepts_indices=[0, 1, 2],\n",
                "    activation_granularity=ActivationGranularity.SAMPLE,\n",
                "    llm_interface=OpenAILLM(api_key=os.environ[\"OPENAI_API_KEY\"]),\n",
                "    sampling_method=SAMPLING_METHOD.TOP,\n",
                "    inputs=rotten_tomatoes[:20],\n",
                "    k_context=3,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for concept_id, label in interpretations.items():\n",
                "    print(f\"Concept {concept_id}: {label}\")"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
